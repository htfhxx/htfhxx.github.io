---
title: 灾难性遗忘问题
date: 2020-11-03
author: 长腿咚咚咚
toc: true
mathjax: true
top: true
categories: NLP进阶
tags:
	- 灾难性遗忘问题
---



## 1 灾难性遗忘

### 1.1 简介

连续学习：根据任务A训练模型后，再根据任务B训练模型，此时对任务A进行测试，还可以维持其重要内容

人工神经网络的连续学习出现问题：由于当前的神经网络对于任务A的参数与任务B的参数基本无关，使得当任务B训练完成后，该网络无法给出任务A的结果

灾难消失：在网络顺序训练多重任务时，对先前任务的重要权重无法保留，称之为灾难性消失。







### 1.2 遗忘的体现



各种论文是如何体现灾难性遗忘的？

* 顺序学习若干任务、若干Atari2600游戏。之前训练的任务效果变化 [3]
* 原预训练语言模型与当前fine-tune模型的参数距离 [2]



* **[11] Learning and Evaluating General Linguistic Intelligence 2019 arxiv**

Catastrophic forgetting in a continual learning setup on unsupervised −→ SQuAD −→ MNLI (top) and unsupervised −→ SQuAD −→ TriviaQA (bottom).

* **[12] Does an LSTM forget more than a CNN? An empirical study of catastrophic forgetting in NLP 2019 ALTA**

旨在了解导致连续学习中遗忘的因素。 主要发现是CNN的遗忘少于LSTM。 实验显示，最大池化是底层的操作，与LSTM相比，它有助于CNN减轻遗忘。 还发现，将艰巨的任务放在任务序列的末尾，可以减少遗忘。 

本文还分析了微调上下文嵌入对灾难性遗忘的影响，发现在持续学习设置中，使用嵌入作为特征提取器优于微调。



### 1.3 连续学习方法分类

* **Replay-based or Rehearsal method**   示例重播方法   存储过去的样本，并定期重播它们。在模型学习新任务的同时混合原来任务的数据。
* **Parameter isolation-based methods**   通过为每个任务更新一组参数并将其冻结为新任务来避免忘记
* **Ensembling:** 当模型学习新任务的时候，**增加新的模型**（可以是显式或者隐式的方式），使得多个任务实质还是对应多个模型，最后把多个模型的预测进行整合。增加子模型的方式固然好，但是每多一个新任务就多一个子模型，对学习效率和存储都是一个很大的挑战。
* **Regularization-based methods**  建议使用额外的正则化术语来回忆以前的知识。在网络参数更新的时候**增加限制**，使得网络在学习新任务的时候不影响之前的知识。
  * data-focused 以数据为中心的方法通过从预先训练的模型中进行知识提炼来规范新任务学习
  * prior-focused 在学习新任务时，以先验为重点的方法将预训练参数的分布视为先验
    * 优先先验的方法，能使模型能够更有效地从预先训练的模型参数中学习更多的常识。



* NLP预训练模型中的知识遗忘问题主要集中在微调上
  * fine-tuning tricks [2] [4] [5] [7] 







## 2 具体工作 - NN

### 2.1 针对NN

* **[3] Overcoming catastrophic forgetting in neural networks    2017 deepmind PNAS**  

连续学习导致了灾难性遗忘。

有可能克服这种局限性并训练网络，这些网络可以维持他们长期未经历的任务的专业知识。 

EWC 通过选择性地减慢对那些任务重要的权重的学习来记住旧任务。 

在网络参数更新的时候增加限制，使得网络在学习新任务的时候不影响之前的知识。



下图非立体图：

<img src="%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98/image-20201103203946336.png" alt="image-20201103203946336" style="zoom:50%;" />



先训练了一个task1的网络，然后直接在task2上fine-tune（上图蓝色）。

问题是，学到task2之后，就会基本忘记task1了（catastrophic forgetting）

那设个限制，在task2上更新网络的时候，不能离第一个网络的参数太远，也就是相对于之前的网络参数上加了l2 regularizaiton（上图绿色）

这样还不行。考虑到网络中有些参数没用有些参数有用，让重要的参数别变太多，就更新不重要的参数（上图红色）



* [6] A Multi-Task Learning Framework for Overcoming the Catastrophic Forgetting in Automatic Speech Recognition  2019 arxiv 

现有自动语音识别（ASR）系统适合目标领域时，例如微调，再训练，经常使用转移学习。 

在这些过程中，系统参数可能与先前学习的参数有很大的偏差。 因此，系统训练过程很难从目标领域学习知识，同时又不忘记先前的学习过程中的知识，这被称为灾难性遗忘（CF）。 

本文提出一种新颖的ASR多任务学习训练框架。认为保留原始知识和学习新知识分别是两个独立的任务。 一方面，我们限制新参数不要偏离原始参数太远，并在忘记原始知识时惩罚新系统。 另一方面，我们强迫新系统快速解决新知识。 然后，采用MTL机制来获得两个任务之间的平衡。 



* **[13] An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models 2019 NAACL  -pc**

提出了一种概念上简单有效的转移学习方法，用于解决灾难性遗忘问题，文本分类任务。 

具体来说，我们将特定于任务的优化函数与辅助语言模型目标结合在一起，该目标可以在培训过程中进行调整。 这样可以保留语言模型捕获的语言规则，同时可以进行充分的调整以解决目标任务。 

我们的方法不需要预先训练或微调网络的各个组成部分，而我们只需一步就可以对模型进行端到端训练。



* **[10] Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in Reading Comprehension 2020 IJCNN**

机器阅读理解任务的灾难性遗忘

不从源域访问数据，引入辅助惩罚项，规范化微调过程



### 2.2 预训练模型 Fine-tune



* **[4] Universal Language Model Fine-tuning for Text Classification 2018 ACL**

一种微调方法，文本分类任务，引入判别性微调倾斜的三角形学习率和针对LM的微调逐渐解冻



* **[5] Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models 2020 ICLR**

一种微调方法，提出dropout的方式将预训练的参数随机混合到下游模型中来减少BERT微调中的遗忘。

只有少量训练实例可用来fine-tune时，会降低性能。

本文介绍了一种新的正则化技术mixout。



* [7] Side-tuning: Network adaptation via additive side networks  2019 arxiv

对于fine-tune，本文提出了一种简单的替代方法：side-tuning 
side-tuning 通过训练轻型side网络来适应预训练的网络，该网络通过求和与**（未更改的）**预训练网络融合。

这种简单的方法与现有解决方案一样好，甚至更好，它解决了一些 微调，固定功能和其他常见方法的基本问题，特别是，侧调不太容易过度拟合，渐近一致，并且不会在增量学习中遭受灾难性的遗忘。



* **[2] Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting EMNLP 2020 https://arxiv.org/pdf/2004.12651.pdf**

动机：预训练+微调这样的迁移学习会遇到灾难性的遗忘问题。

主要工作：提出一种 recall-and-learn 机制，共同学习预训练任务和下游任务。

主要贡献：采用多任务学习的思想解决微调深度预训练语言模型的灾难性遗忘问题；提出预训练仿真和目标转移机制，在没有预训练任务数据的情况下实现多任务微调；提供了开源的优化器

```
灾难性遗忘问题是sequential trasfer learning的一个普遍问题，其体现在遗忘之前的知识而在目标领域上过度拟合。
目前已有的工作主要集中在fine-tune的trick上，[23] 引入判别性微调倾斜的三角形学习率和针对LM的微调逐渐解冻，[36] 提出dropout的方式将预训练的参数随机混合到下游模型中来减少BERT微调中的遗忘；
不同于顺序的进行预训练和下游任务的训练，多任务学习同时进行两者。但是这些多任务学习的工作 1要使用大规模预训练数据 2我们只下游任务的性能。
因此本文提出一种Recall—and-learn机制，在fine-tune过程中采用预训练作为辅助学习任务。
本文贡献的两方面：Pretraining Simulation解决大规模预训练数据不可获取的问题；Objective Shifting将多任务学习的目标逐渐转移到下游任务目标（本质上就是动态的调整loss比例）
```

实验：General Language Understanding Evaluation (GLUE) benchmark （9个任务）

思考：如果只在乎下游任务，灾难性的遗忘问题好像不太重要？（再调研一下灾难性遗忘的体现与分析）









### 2.3 其他

知识注入PLM的知识遗忘问题

* **[1] K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters**

动机：将知识注入大型预训练模型，现有方法会更新原始参数，遭受灾难性的遗忘。

主要工作：提出K-Adapter，保持原始预训练模型参数固定，并支持知识注入。

![image-20201028102828012](%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98/image-20201028102828012.png)

之前的工作都更新了预训练模型的参数，导致灾难性遗忘之前注入的知识。

通过集成紧凑的神经模型（适配器）来实现的

![image-20201028103214978](%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E9%97%AE%E9%A2%98/image-20201028103214978.png)

比较大的问题：只有实验结果ok，没有分析遗忘程度的减少





## IDEA?



**一般的灾难性遗忘：**

* 在任务A上train一个model_1，任务A效果ok；
* 然后将model_1在任务B上继续train得到model_2，任务B效果ok；

然而这个时候model_2在任务A上的效果比model_1差



**预训练模型的灾难性遗忘场景：**

```
* pretrain 得到PLM
* fine-tune 得到 模型fine-tune1   
fine-tune过程中，造成了预训练过程学到的内容 灾难性的遗忘，导致目标任务效果没有那么理想
但目前没有找到有分析遗忘具体体现在哪的工作，只有通过fine-tune的效果提升来体现
```

```
* pretrain 得到PLM
* 任务1上fine-tune 得到 模型fine-tune1
* fine-tune1 在任务2 上fine-tune 得到 模型fine-tune2
```

```
model_1(PLM)进行fine-tune，model_4和model_3的效果哪个好？
（真实场景？）
- 小批量数据A 对PLM进行fine-tune  得到model_2
- 又来了一批数据B 使用B对model_2进行fine-tune  得到model_3

（真实场景2，但是ab数据集大）
- 小批量数据A 对PLM进行fine-tune  得到model_2
- 又来了一批数据B 使用A+B对model_2进行fine-tune  得到model_4

（不真实的场景）
-- 所有数据A+B一口气全到位 对PLM进行fine-tune  得到model_5
```





基于 预训练模型的灾难性遗忘问题挖掘了几个研究点：

针对预训练+fine-tune的过程（遗忘预训练）

1. 预训练模型fine tune时对之前pretrain内容的遗忘 如何体现？
2. 预训练模型fine tune后对之前pretrain内容的遗忘问题如何解决？



针对预训练+多次fine-tune的过程（遗忘预训练+之前的fine-tune）

1. 预训练模型多次fine-tune过程的遗忘分析（更多的是因为pretrain过程的进一步的遗忘 还是上一fine-tune阶段的遗忘）
2. 预训练模型多次fine tune时，对之前finetune内容的遗忘问题。（预训练模型迁移学习下的增量学习）

问题比较大，暂时很难找到一个切入点，暂时搁置一下，目前先做面向匹配任务的预训练模型。







## Reference

https://blog.csdn.net/u010195841/article/details/69257897

https://www.cnblogs.com/chason95/articles/9892560.html

https://blog.csdn.net/zyy617532750/article/details/104217399



