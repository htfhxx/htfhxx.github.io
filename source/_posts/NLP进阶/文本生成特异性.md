---
title: 文本生成特异性
date: 2020-05-23 23:02:00
author: 长腿咚咚咚
toc: true
mathjax: true
top: true
categories: NLP进阶
tags:
	- 文本生成特异性
---

[TOC]

## 1 问题背景

文本生成的安全响应问题，例如在对话领域，容易生成无意义的安全回答，例如”我不知道“。

倾向于返回高频但毫无意义响应的原因，一部分在于以往的方法针对一对一关系进行建模，忽略了可能的一对多的关系。





目前的方法汇总：

1. 找到一个更好的目标函数

2. 改进排序规则（训练成本低）  90   70   91  92   93

3. 引入潜在变量  94  82  95  96 97      很难解释，变量很难建模
4. 引入主题 101   103







## 2 评估

相关性：PPL、BLEU1、BLEU2

多样性：distinct-1、 distinct-2

其他：人工评估



论文[4]中使用了：distinct-1 & distinct-2、BLEU

#论文[1]中使用了：distinct-1 & distinct-2 （count numbers of distinct unigrams and bigrams in the generated responses）、BLEU、Average & Extrema（映射到向量空间中求余弦相似度，参考论文[2]）、人工评估。









## 3 相关工作

###  3.1 目标函数改进

论文[4] 是较为早期的这方面的工作，它从目标函数入手。

一般的模型是以最大似然函数为目标函数，分数最高的回复通常是最常见的句子，更有意义的回复也会出现在N-best列表（beam search的结果）中，但是分数会相对低一些。此论文在模型中使用最大互信息作为目标函数。

最大似然函数，就是给定Source得到Target的概率最大；而加入了互信息，就相当于加入了source和target之间的相关性。

论文一共提出俩基于MMI的损失函数。

一个是：

![image-20200526190648554](文本生成特异性\image-20200526190648554.png)

来源于以下互信息公式的改动：

![image-20200526190700851](文本生成特异性\image-20200526190700851.png)

另一个是：

![image-20200526190731459](文本生成特异性\image-20200526190731459.png)



其他的方法或多或少的都涉及目标函数的改进。



### 3.2 解码过程改进排序规则



### 3.3 引入潜在变量 

论文[1]是对话特异性的工作，避免生成无意义回答，例如”我不知道“。论文提出了一种新颖的受控反应产生机制，核心是输入了一个控制变量。

整体任务的输入除了utterence之外，还有一个范围是0-1的控制变量，这个控制变量通过高斯核层与单词的用法表示进行交互，指导模型生成不同特异性级别的响应。至于单词的用法表示，作者假设每个单词，除了与其含义相关的语义表示之外，在不同的响应目的下，还具有与使用偏好相关的另一个表示，将此表示形式称为单词的用法表示形式。

最后的概率由两部分组成，一部分是常规seq2seq的decoder得到的，一部分是包含了控制变量、单词用法表示、高斯核层的一个概率。（花里胡哨听得美妙）

原始数据中并没有这个控制变量，论文通过远程监督的方式去获取，并且描述了两种获取特异性控制变量的远距离标签的方法。两种方法分别是根据回复整体或者回复内词语的频率来打标签。

![image-20200525182333650](文本生成特异性\image-20200525182333650.png)



论文[6] 提到以往的生成模型倾向于返回高频但毫无意义的响应，论文提出不同的source和不同的responce本身存在一对一的关系， 例如，考虑输入“您吃过饭了吗？”  （在汉语中，该词广泛用于问候），喜欢修辞问题的受访者可以回答“你呢？”。 相反，喜欢陈述性句子的被访者可以肯定地回答“是的，我有”。

论文提出了一种机制感知的响应机（MARM）的概率框架，假设存在一些潜在的响应机制，每种机制都可以为单个输入生成不同的响应。 在这种假设下，将不同的响应机制建模为潜在的嵌入，并开发了一种编码器-分离器-解码器（encoder-diverter-decoder ）框架，以端到端的方式训练其模块，其中diverter用于生成机制感知的上下文。

依赖于机制的响应生成这有助于将不合语法的输出与有意义但不频繁的响应区分开。对于输入x，有三种可能的输出，一种是概率大的常见响应，一种是概率小的错误语法响应，一种是有意义但不常见且概率也小的输出。diverter是为了将后两者区分开。然后相当于通过 latent responding factors 去建模多响应的机制。

说这么复杂，本质上就是对于一个输入x，挑选最可能的topL个机制，解码时每个机制得到K个回答，这L乘K个回答进行一个rerank。但是也有弊端，这种 latent  factors 很难去解释和确定factor的数量。



<img src="文本生成特异性\image-20200526205910691.png" alt="image-20200526205910691" style="zoom: 67%;" />





论文[7] 提到seq2seq将不同的响应规律建模为一对一映射。

有前途的方法主要结合多种潜在机制来建立一对多关系，但是在训练过程中，如果没有准确选择与目标响应相对应的潜伏机制，这些方法就会对潜伏机制进行粗略的优化。此论文提出了一种多映射机制来更好地捕获一对多关系，其中多个映射模块被用作潜在机制来对从输入帖子到其不同响应的语义映射进行建模。 为了精确优化潜在机制，设计了后映射选择模块，根据目标响应选择对应的映射模块进行进一步的优化。 还介绍了辅助匹配损失，以帮助优化后映射选择。 

论文的贡献点在于提出了一种多重映射机制来捕获具有多个映射模块的一对多关系作为潜在机制，更具灵活性和可解释性。还提出了一种新颖的后部映射选择模块，以根据训练过程中的目标反应选择相应的映射模块，从而确保更准确地优化潜在机制。 还引入了辅助匹配损失，以促进后映射选择的优化。

![image-20200527140704469](%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E7%89%B9%E5%BC%82%E6%80%A7/image-20200527140704469.png)



过程中，分别对post和responce编码，然后对post进行一个线性映射，映射到K个不同的responce表达中。然后从K个模块中选择响应的映射模块，引入了分类分布 π 来表示以目标响应为条件的响应，本质上就是一个m与y的内积+softmax。另外这个映射模块在测试过程中是随机挑选的。

实验过程中，发现映射挑选过程倾向于挑选相同的模块，模型陷入单个映射模块的局部最优。为了解决这个问题，加入了一个辅助目标，以改进responce部分的编码，即post和responce的相关性概率（内积）





论文 [9] 提出了一种对话生成模型，该模型直接捕获对对应输入的responce，从而减少了确定性对话模型的“无聊输出”问题。 

<img src="文本生成特异性\image-20200527180529646.png" alt="image-20200527180529646" style="zoom:67%;" />



论文[11] -2019 针对于对话生成多样性和相关性的联合优化。

论文中提出一种新颖的几何(?)的方法，利用了两种不同的模型，一个seq2seq产生预测的响应，一个ae产生潜在的响应，并且为了共享相同的潜在空间，使用了同一个解码器，并进行联合训练。论文强调了加入了正则化项的必要性，只共享解码器不一定会对齐两者的潜在空间，两个正则化项分别是：插值项Linterp，融合项Lfuse。

![image-20200608130132530](文本生成特异性\image-20200608130132530.png)

![image-20200608130145180](文本生成特异性\image-20200608130145180.png)

![image-20200608130032872](文本生成特异性\image-20200608130032872.png)

![image-20200601163800516](文本生成特异性\image-20200601163800516.png)



论文[13] 建立短文本对话生成输入和输出的一对多映射。

模型的输入是x对应的集合y，对于每一个x，都设定有一个对应的隐变量z，并通过两个限制条件（合理地）将z设定为词典中的词。

两个模型交替训练，左边得到一些词，右边得到z的反馈。

<img src="文本生成特异性\image-20200601195532257.png" alt="image-20200601195532257" style="zoom:67%;" />



### 3.4 引入主题或其他信息

论文[3] 也是基于seq2seq的聊天机器人，为了生成有益的有趣的responce，论文将主题信息融入了seq2seq框架中，减少“我也是”，“我看到”或“我不知道”之类的琐碎响应。

输入的信息中通过其他语料预训练过的LDA提取出主题词，将输入信息和主题词分别编码后，通过attention机制，在解码过程中上下文向量和主题向量共同影响responce的生成，并修改loss，除原decoder之外还加入了主题相关的概率项。

综上，论文主要在于将主题词作为先验，并且改进了seq2seq。

<img src="文本生成特异性\image-20200525231737567.png" alt="image-20200525231737567" style="zoom:67%;" />



论文[8] 在对话生成的过程中，加入了一些Meta-Words，通过这些信息的辅助，显式建模一对多关系。

<img src="文本生成特异性\image-20200527161032014.png" alt="image-20200527161032014" style="zoom:67%;" />

具体而言，论文提出了一个goal tracking memory network: GTMN，在seq2seq的基础上，加入了状态存储模块和状态控制器。在编码过程中使用双向GRU，加入状态控制，使用meta-words初始化这个目标追踪网络，在解码过程中meta-words由状态控制器来更新，通过目前状态与目标的差异来控制解码。

损失方面，除了负对数可能性之外，还提出了最小化状态更新损失，该状态更新损失可以直接监督基于基本事实的存储网络的学习。 

![image-20200527162231630](文本生成特异性\image-20200527162231630.png)



论文[14] 使用逐点互信息来选取单词作为关键字，再将这个关键字来解码得到responce。

<img src="文本生成特异性\image-20200601201056052.png" alt="image-20200601201056052" style="zoom:67%;" />



论文[15] 集中于在学习过程中选择适当的知识，进而帮助对话的多样性。

训练过程的输入为，utterence、N个knowledge、response，输出为responce。测试过程中不输入responce。

将输入x、y、k进行编码后，计算给定x得到各个知识的先验概率，以及给定x、y得到各个k的后验概率，求两者的KL散度作为损失项之一。

然后将knowledge manager选定的某个k和x都输入decoder，得到y，这是一个loss。根据y和知识得到一个bow loss。



<img src="文本生成特异性\image-20200601222330314.png" alt="image-20200601222330314" style="zoom:67%;" />

<img src="文本生成特异性\image-20200601222628334.png" alt="image-20200601222628334" style="zoom:67%;" />



论文[16] 是一篇workshop。提出了较为简单的结构，用到了positive pointwise mutual information， 首先从source中识别关键词，并鼓励用关键词生成响应。

![image-20200602160320001](文本生成特异性\image-20200602160320001.png)



论文[10] 的任务定义是，输入：sentence和style id，输出sentence

将sentence和id进行concat，然后投入decoder，每一步得到一个期望字符词向量，然后将得到的期望字符词向量分布于风格表示分布的互信息加入loss。

<img src="文本生成特异性\image-20200601152621511.png" alt="image-20200601152621511" style="zoom:67%;" />

### 3.5 其他

论文[5] 提出一种方法，这种方法涉及数据提炼和模型训练之间的交替进行。删除上一轮训练的模型最常见的responce的数据，然后在剩余数据中重新训练模型。不同程度的数据提炼训练的模型表现出不同的特异性水平。

论文还训练了一个强化学习系统，来调整生成模型。下面是数据蒸馏的伪代码：

<img src="文本生成特异性\image-20200526201502467.png" alt="image-20200526201502467" style="zoom:67%;" />

实验效果看起来很有意思，随着数据蒸馏，在验证集上的损失和困惑度越来越大的同时，代表多样性的指标distinct-1和distinct-2增大不少。（不过也可以归结为迭代次数带来的，这方面并没有对比实验）

![image-20200526202512565](文本生成特异性\image-20200526202512565.png)



论文[12] ，为对话生成提出了一个新的范式，即原型-编辑，它首先从预定义的索引中检索原型响应，然后根据原型上下文和当前上下文之间的差异来编辑原型响应。 我们的动机是，检索到的原型在语法上和信息量方面都提供了一个很好的生成起点，并且后期编辑过程进一步提高了原型的相关性和连贯性。 在实践中，我们设计了一个基于上下文的编辑模型，该模型建立在以编辑矢量为补充的编码器-解码器框架上。 我们首先通过考虑原型上下文和当前上下文之间的词汇差异来生成编辑矢量。 之后，将编辑矢量和原型响应表示馈送到解码器以生成新的响应。 

<img src="文本生成特异性\image-20200601164849456.png" alt="image-20200601164849456" style="zoom:67%;" />



## 4 模型层面





### 论文[6] Mechanism-Aware Neural Machine for Dialogue Response Generation    2017

论文[6] 提到以往的生成模型倾向于返回高频但毫无意义的响应，论文提出不同的source和不同的responce本身存在一对一的关系， 例如，考虑输入“您吃过饭了吗？”  （在汉语中，该词广泛用于问候），喜欢修辞问题的受访者可以回答“你呢？”。 相反，喜欢陈述性句子的被访者可以肯定地回答“是的，我有”。

论文提出了一种机制感知的响应机（MARM）的概率框架，假设存在一些潜在的语言机制，每种机制都可以为单个输入生成不同的响应。 在这种假设下，将不同的响应机制建模为潜在的嵌入，并开发了一种编码器-分离器-解码器（encoder-diverter-decoder ）框架，以端到端的方式训练其模块，其中diverter用于生成机制感知的上下文。

对encoder-decoder模型的中间产物context vector c进行分类，得到概率最大的机制 ![[公式]](https://www.zhihu.com/equation?tex=m_%7Bi%7D) ,然后将 ![[公式]](https://www.zhihu.com/equation?tex=m_%7Bi%7D) 与context vector 进行拼接作为decoder的输入，解码出生成的回复。

![[公式]](https://www.zhihu.com/equation?tex=p%28y%7Cx%29%3D%5Csum_%7Bi%3D1%7D%5E%7BM%7D%7Bp%28y%2Cm_i%7Cx%29%7D%3D%5Csum_%7Bi%3D1%7D%5E%7BM%7D%7Bp%28m_i%7Cx%29p%28y%7Cm_i%2Cx%29%7D)

（这段忘了从哪来的了）依赖于机制的响应生成这有助于将不合语法的输出与有意义但不频繁的响应区分开。对于输入x，有三种可能的输出，一种是概率大的常见响应，一种是概率小的错误语法响应，一种是有意义但不常见且概率也小的输出。diverter是为了将后两者区分开。然后相当于通过 latent responding factors 去建模多响应的机制。

在最后结果生成的过程中，就是对于一个输入x，挑选最可能的topL个机制，解码时每个机制得到K个回答，这L乘K个回答进行一个rerank，rerank的方式是：

![image-20200612174004215](文本生成特异性\image-20200612174004215.png)





<img src="文本生成特异性\image-20200526205910691.png" alt="image-20200526205910691" style="zoom: 67%;" />



### 论文[17] Elastic responding machine for dialog generation with dynamically mechanism selecting.  2018 AAAI

论文[6]工作的延伸。

之前的**encoder-diverter-decoder模型**，对encoder-decoder模型的中间产物context vector c进行分类，得到概率最大的机制 ![[公式]](https://www.zhihu.com/equation?tex=m_%7Bi%7D) ,然后将 ![[公式]](https://www.zhihu.com/equation?tex=m_%7Bi%7D) 与context vector 进行拼接作为decoder的输入，解码出生成的回复。

本文作者在前文的基础上，又加入了Filter模块，作者的目的是从所有mechanism集合中选出一个子集 ![[公式]](https://www.zhihu.com/equation?tex=S_x) ，包含足够多的mechanism，能够生成多种style的response。这个子集 ![[公式]](https://www.zhihu.com/equation?tex=S_x) 需要满足两个条件：1）包含足够多的mechanism；2）子集的mechanism没有太高的重复性，没有冗余。选中了子集 ![[公式]](https://www.zhihu.com/equation?tex=S_x) 后，生成response ![[公式]](https://www.zhihu.com/equation?tex=y) 的概率为

![[公式]](https://www.zhihu.com/equation?tex=p%28y%7Cx%29%3D%5Cfrac+%7B%5Csum_%7Bm+%5Cin+S_x%7D%5E%7B%7D%7Bp%28m%7Cx%29p%28y%7Cm%2Cx%29%7D%7D%7B%5Csum_%7Bm+%5Cin+S_x%7D%5E%7B%7D%7Bp%28m%7Cx%29%7D%7D)

使用强化学习选择子集，选出包含 ![[公式]](https://www.zhihu.com/equation?tex=K)个mechanism之后，依次将 ![[公式]](https://www.zhihu.com/equation?tex=c) 和 ![[公式]](https://www.zhihu.com/equation?tex=m_i%28m_i+%5Cin+S_x%29) 连接在一起输入到decoder中生成各自mechanism对应的response。

<img src="文本生成特异性\image-20200612173719071.png" alt="image-20200612173719071" style="zoom: 50%;" />





### 论文[7] Generating Multiple Diverse Responses with Multi-Mapping and Posterior Mapping Selection 2019

论文[7] -2019 提到seq2seq将不同的响应规律建模为一对一映射。

有前途的方法主要结合多种潜在机制来建立一对多关系，但是在训练过程中，**如果没有准确选择与目标响应相对应的潜伏机制，这些方法就会对潜伏机制进行粗略的优化**。

为了获得更准确的建模，我们假设仅应选择与目标响应相对应的潜在机制进行优化。 例如，给定一个询问响应，我们应该仅优化对询问响应规律进行建模的潜在机制，而不是其他无关的规律。 尽管在某些方法中，对每个潜在机制的优化是由输入帖子中的权重决定的，但考虑到输入帖子和目标响应之间的语义差距，该权重并不代表相应的潜在机制的选择。

**此论文提出了一种多映射机制来更好地捕获一对多关系，其中多个映射模块被用作潜在机制来对从输入的post到其不同响应的语义映射进行建模。 为了精确优化潜在机制，设计了后映射选择模块，根据目标响应选择对应的映射模块进行进一步的优化。 还介绍了辅助匹配损失，以帮助优化后映射选择。** 

因此论文的贡献点在于提出了一种多重映射机制来捕获具有多个映射模块的一对多关系作为潜在机制，更具灵活性和可解释性。还提出了一种新颖的后部映射选择模块，以根据训练过程中的目标反应选择相应的映射模块，从而确保更准确地优化潜在机制。 还引入了辅助匹配损失，以促进后映射选择的优化。

<img src="文本生成特异性\image-20200527140704469.png" alt="image-20200527140704469" style="zoom: 67%;" />

过程中，分别对post和responce编码，然后对post进行一个线性映射，映射到K个不同的responce表达中。然后从K个模块中选择响应的映射模块，引入了分类分布 π 来表示以目标响应为条件的响应，本质上就是一个m与y的内积+softmax。另外这个映射模块在测试过程中是随机挑选的。

实验过程中，发现映射挑选过程倾向于挑选相同的模块，模型陷入单个映射模块的局部最优。为了解决这个问题，加入了一个辅助目标，以改进responce部分的编码，即post和responce的相关性概率（内积）



### 











## Reference

**[1] Learning to Control the Specificity in Neural Response Generation.   2018**

[2] Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C Courville, and Yoshua Bengio. 2017. A hierarchical latent variable encoder-decoder model for generating dialogues.   In AAAI.  2017

[3] Topic Aware Neural Response Generation.   2018

[4] A Diversity-Promoting Objective Function for Neural Conversation Models.  2016

[5] Data Distillation for Controlling Specificity in Dialogue Generation   2017

[6] Mechanism-Aware Neural Machine for Dialogue Response Generation    2017

[7] Generating Multiple Diverse Responses with Multi-Mapping and Posterior Mapping Selection    2019

[8] Neural Response Generation with Meta-Words  2019

[9] Latent Variable Dialogue Models and their Diversity    2017

[10] Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement 2018

[11] Jointly Optimizing Diversity and Relevance in Neural Response Generation    2019

[12] Response Generation by Context-Aware Prototype Editing   AAAI 2019    数据集不支持模型不具有太多参考性

[13] Generating Multiple Diverse Responses for Short-Text Conversation   AAAI  2019

[14] Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation  2016

[15] Learning to Select Knowledge for Response Generation in Dialog Systems  2019  

[16] Relevant and Informative Response Generation using Pointwise Mutual Information  2019workshop

[17] Elastic responding machine for dialog generation with dynamically mechanism selecting.  2018 AAAI

[18] Get the point of my utterance! learning towards effective responses with multi-head attention mechanism.   2018IJCAI





## End









































# 大大

$$
a_i 
$$











