---
title: 无监督学习
date: 2020-01-05
author: 长腿咚咚咚
toc: true
mathjax: true
categories: machine-learning
tags:
	- 无监督学习
---

[TOC]

## 1 聚类

* 聚类定义：根据数据中样本与样本之间的距离或相似度，将样本划分为若干组／类／簇
* 划分的原则：类内样本距离小、类间样本距离大
* 聚类类型
  1. 基于划分的聚类（无嵌套）
  2. 层次聚类（嵌套）
* 聚类分析的“三要素”
  1. 如何定义样本点之间的“远近”：使用相似性/距离函数
  2. 如何评价聚类出来的簇的质量
  3. 如何获得聚类的簇

* 距离度量函数

  1. 闵可夫斯基（Minkowski）距离：p为1时为曼哈顿距离，p为2时为欧氏距离
     $$
     \operatorname{dist}\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\left(\sum_{d=1}^{D}\left|x_{i d}-x_{j d}\right|^{p}\right)^{1 / p}
     $$

  2. 余弦相似度(cosine similarity)
     $$
     s\left(\mathbf{x}_{i}, \mathbf{x}_{j}\right)=\frac{\sum_{d=1}^{D} x_{i d} x_{j d}}{\sqrt{\sum_{d=1}^{D} x_{i d}^{2}} \sqrt{\sum_{d=1}^{D} x_{j d}^{2}}}=\frac{\mathbf{x}_{i}^{T} \mathbf{x}_{j}}{\left\|\mathbf{x}_{i}\right\|\left\|\mathbf{x}_{j}\right\|}
     $$

  3. 相关系数（Pearson系数）
  4. 杰卡德相似系数(Jaccard)

* 聚类性能评价指标

  1. 外部评价法(external criterion) ：聚类结果与参考结果有多相近
  2. 内部评价法(internal criterion)：聚类的本质特点（无参考结果）。簇内相似度越高，聚类质量越好；簇间相似度越低，聚类质量越好。

* 经典聚类算法

  1. K均值聚类（K-means）
  2. 高斯混合模型和最大期望算法（Gaussian Mixture Models and Expectation- Maximization Algorithm）
  3. 层次聚类
  4. 基于密度聚类

  

## 2 K均值聚类（K-means）

* 算法流程

<img src="%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1578206576314.png" alt="1578206576314" style="zoom:50%;" />

* 运行示意

<img src="%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1578206607286.png" alt="1578206607286" style="zoom:50%;" />

* 一些细节

  * 如何划分节点：使用欧式距离进行距离度量，每个节点都划分到最近的那个质心的簇中

  * 优化目标（损失函数）
    $$
    \quad J=\sum_{i=1}^{N} \sum_{k=1}^{K} r_{i k}\left\|\mathbf{x}_{i}-\boldsymbol{\mu}_{k}\right\|^{2}  \\ 从属度:r_{i,k} ∈ {0,1}  \\ u_k是类中心点
    $$

* K-Means的局限性
  K-Means假定簇为球形且每个簇的概率相等。

  当簇具有不同的尺寸、密度、簇非球形时，结果不理想；
  离群点的影响





## 3 EM算法与高斯混合模型

### 3.1 EM算法

* EM算法流程

  * 输入：观测变量数据Y，隐变量数据Z，联合分布$P(Y,Z | \theta )$，条件分布 $P(Y| Z , \theta )$；
  * 输出：模型参数 $\theta$

  1. 选择模型参数的初始值$\theta _{0}$，开始迭代

  2. E步，计算在模型参数固定为$\theta _{0}$的情况下的**观测数据的概率**：
     $$
     \begin{aligned}
     Q\left(\theta, \theta^{(i)}\right) &=E_{Z}\left[\log P(Y, Z | \theta) | Y, \theta^{(i)}\right] \\
     &=\sum_{Z} \log P(Y, Z | \theta) P\left(Z | Y, \theta^{(i)}\right)
     \end{aligned}
     $$

  3. M步，当前观测数据概率下，通过极大似然估计来估计参数
     $$
     \theta^{(i+1)}=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)
     $$

  4. 重复2、3，直到收敛





### 3.2 高斯混合模型









## 4 层次聚类





##  5 基于密度的聚类

* DBSCAN( density-based spatial clustering ofapplication with noise）



















## Reference

```
《模式识别与机器学习》  ——from UCAS
```

